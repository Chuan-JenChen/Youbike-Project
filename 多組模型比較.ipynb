{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares the CV perfromance of a set of predetrmined models\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "Bike = pd.read_csv(\"D:/BDSE26/ML_input_Sep01.csv\",sep = \",\", nrows = 10000)\n",
    "ds= DataFrame(Bike)\n",
    "X_choice = ds.loc[:,['Hr','MRT_Out_ppl','holiday','school_off','Temperature','RH','WS','Precp']]\n",
    "kmeansModel = KMeans(n_clusters=10, random_state=46)\n",
    "clusters_pred = kmeansModel.fit_predict(X_choice)\n",
    "X_choice ['k_meeans'] = clusters_pred\n",
    "ds = X_choice.values\n",
    "X = ds[:,1:6]\n",
    "y = ds[:,7]\n",
    "y= y.astype('int64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j8003\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 建立不同模型\n",
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier()\n",
    "    ]\n",
    "# 訓練不同模型\n",
    "for i, _ in enumerate(models):\n",
    "    models[i].fit(X_train, y_train)\n",
    "for i, _ in enumerate(models):\n",
    "   y_pred = models[i].predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i, _ in enumerate(models):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1912\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1912\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1912\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1912\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1912\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        18\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        15\n",
      "           8       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for i, _ in enumerate(models):\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deeping_learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e1a3bf3d86847cc809fc6f272d9d5af5161950dd9d11db4821122eb24908ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
