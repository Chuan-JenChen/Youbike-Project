{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bike = pd.read_csv(\"D:/BDSE26/day.csv\",sep = \",\")\n",
    "ds = Bike.values\n",
    "X = ds[:, 2:14]\n",
    "y = ds[:, 15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansModel = KMeans(n_clusters=4, random_state=46)\n",
    "clusters_pred = kmeansModel.fit_predict(X)\n",
    "Bike ['k_meeans'] = clusters_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "ds = Bike.values\n",
    "X = ds[:, 2:15]\n",
    "y = ds[:, 16]\n",
    "y= y.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "每轮迭代运行结果:{'mean_fit_time': array([0.86384411, 0.73942938, 0.71304445, 0.81356993, 0.94381323,\n",
      "       0.81318178]), 'std_fit_time': array([0.07370819, 0.03244925, 0.01513678, 0.08383908, 0.04560682,\n",
      "       0.10992914]), 'mean_score_time': array([0.00917554, 0.00296054, 0.00279279, 0.00290356, 0.00219431,\n",
      "       0.00279274]), 'std_score_time': array([7.52730963e-03, 6.20367892e-05, 7.46531348e-04, 8.06688290e-04,\n",
      "       3.98922166e-04, 7.46518635e-04]), 'param_gamma': masked_array(data=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'gamma': 0.1}, {'gamma': 0.2}, {'gamma': 0.3}, {'gamma': 0.4}, {'gamma': 0.5}, {'gamma': 0.6}], 'split0_test_score': array([0.96919879, 0.96888649, 0.96735757, 0.96355535, 0.96321062,\n",
      "       0.96122412]), 'split1_test_score': array([0.89941927, 0.90463212, 0.89692169, 0.90654173, 0.90299315,\n",
      "       0.90409585]), 'split2_test_score': array([0.9466896 , 0.94779929, 0.94583696, 0.94383569, 0.94086077,\n",
      "       0.94269799]), 'split3_test_score': array([0.86652451, 0.86997106, 0.86981248, 0.87038422, 0.87219907,\n",
      "       0.87458691]), 'split4_test_score': array([0.92000209, 0.92466244, 0.91843889, 0.91716359, 0.91735214,\n",
      "       0.91647706]), 'mean_test_score': array([0.92036685, 0.92319028, 0.91967352, 0.92029612, 0.91932315,\n",
      "       0.91981639]), 'std_test_score': array([0.03582004, 0.03427128, 0.03453574, 0.03198645, 0.03124488,\n",
      "       0.03014021]), 'rank_test_score': array([2, 1, 5, 3, 6, 4])}\n",
      "参数的最佳取值：{'gamma': 0.2}\n",
      "最佳模型得分:0.9231902797701806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ds = Bike.values\n",
    "    X = ds[:, 2:15]\n",
    "    y = ds[:, 16]\n",
    "    y= y.astype('int')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "    cv_params = {'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "    other_params = {'learning_rate': 0.1, 'n_estimators': 550, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,\n",
    "                    'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "    model = xgb.XGBRegressor(**other_params)\n",
    "    optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)\n",
    "    optimized_GBM.fit(X_train, y_train)\n",
    "    evalute_result = optimized_GBM.cv_results_\n",
    "    print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "    print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "    print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j8003\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:21.60208\n",
      "[1]\ttrain-rmse:19.55555\n",
      "[2]\ttrain-rmse:17.71453\n",
      "[3]\ttrain-rmse:16.06071\n",
      "[4]\ttrain-rmse:14.57054\n",
      "[5]\ttrain-rmse:13.23501\n",
      "[6]\ttrain-rmse:12.03721\n",
      "[7]\ttrain-rmse:10.94916\n",
      "[8]\ttrain-rmse:9.98378\n",
      "[9]\ttrain-rmse:9.10604\n",
      "[01:17:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:17.06433\n",
      "[1]\tvalidation_0-rmse:12.27140\n",
      "[2]\tvalidation_0-rmse:8.92523\n",
      "[3]\tvalidation_0-rmse:6.56554\n",
      "[4]\tvalidation_0-rmse:4.88678\n",
      "[5]\tvalidation_0-rmse:3.70939\n",
      "[6]\tvalidation_0-rmse:2.89225\n",
      "[7]\tvalidation_0-rmse:2.33943\n",
      "[8]\tvalidation_0-rmse:1.94412\n",
      "[9]\tvalidation_0-rmse:1.66867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=0, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=10, n_jobs=6,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, silent=False, subsample=1,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "ds = Bike.values\n",
    "X = ds[:, 2:15]\n",
    "y = ds[:, 16]\n",
    "y= y.astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "print('3-fold cross validation:\\n')                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.02) [KNN]\n",
      "Accuracy: 0.91 (+/- 0.03) [Random Forest]\n",
      "Accuracy: 0.70 (+/- 0.20) [Naive Bayes]\n",
      "Accuracy: 0.91 (+/- 0.03) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['KNN', 'Random Forest', 'Naive Bayes','StackingClassifier']):\n",
    "                    scores = model_selection.cross_val_score(clf, X, y,cv=3, scoring='accuracy')\n",
    "                    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"%(scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06f7e3047e2e3db8a299497334c0b4daa5adaa570f351f4abd94e979a4fd6932"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
